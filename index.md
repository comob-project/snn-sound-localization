<!-- This is the home page of the jupyterbook website, hence why it is in the root directory. -->

# About
<!-- This title is what appears in the TOC (left nav sidebar) -->

<br>

Welcome! This is a collaborative project where we model **sound localization** in the brain. How do neurons compute _where_ a sound is coming from, using just the signals in both ears? To investigate this, we train **spiking neural network** (SNN) models and analyze them.

We aim to work together on this, openly, and write a massive, joint paper. Everyone who contributes gets to be an author of that paper, regardless of whether or not their work is included in the final draft.

[Read on](Contributing.md) for how to join and contribute to this project.


## Context

This project is part of [COMOB](https://comob-project.github.io/), the project for collaborative modelling of the brain. It grew out of [Dan Goodman's tutorial][tut] for the 2022 _Cosyne_ conference.

That tutorial gave a brief introduction to SNN models, and to the **surrogate gradient descent** method for training them. The tutorial's course materials are [freely available online][tut].

[tut]: https://neural-reckoning.github.io/cosyne-tutorial-2022/
