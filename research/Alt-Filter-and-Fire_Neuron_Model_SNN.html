
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Filter-and-Fire Neuron Model &#8212; SNN Sound Localization</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style-mods.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://comob-project.github.io/snn-sound-localization/research/Alt-Filter-and-Fire_Neuron_Model_SNN.html" />
    <link rel="shortcut icon" href="../_static/headphone-logo.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Altering Output Neurons" href="Altering_output_neurons.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">SNN Sound Localization</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   About
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Contributing.html">
   How to contribute
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/comob-project/snn-sound-localization/discussions/categories/q-a">
   Discussion forum
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Research
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Background.html">
   Background
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Questions.html">
   Questions &amp; challenges
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Starting-Notebook.html">
   Starting Notebook
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Workshop_1_Write_Up.html">
   Workshop 1 Write-up
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Solving_problem_with_delay_learning.html">
   Vanilla sound localization problem with a single delay layer (non-spiking)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Quick_Start_250HzClassification_CleanVersion.html">
   Quick Start Notebook with 250 Hz input
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="SNN_sound_W1W2_threshold_plot.html">
   Modified from starting Notebook
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Quick_Start_250HzClassification.html">
   Quick Start Notebook with 250 Hz input
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Optimizing-Membrane-Time-Constant.html">
   Improving Performance: Optimizing the membrane time constant
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Quick_Start.html">
   Quick Start Notebook
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Noise_robustness.html">
   Robustness to Noise and Dropout
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Learning_delays_major_edit2.html">
   Learning delays
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="IE-neuron-distribution.html">
   Analysing Dale’s law and distribution of excitatory and inhibitory neurons
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Excitatory-only-localisation.html">
   Sound localisation with excitatory-only inputs surrogate gradient descent
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Dynamic_threshold.html">
   Dynamic threshold
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Dales_law.html">
   Sound localisation following Dale’ law
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Dales_Law_Follow_Up.html">
   Analysing Dale’s law and distribution of excitatory and inhibitory neurons
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Compute%20hessians%20%28jax%20version%29.html">
   Compute hessians (jax version)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Analysing-Trained-Networks.html">
   (WIP) Analysing trained networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Analysing-Trained-Networks-Part2.html">
   Analysing trained networks - workshop edition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Altering_output_neurons.html">
   Altering Output Neurons
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Filter-and-Fire Neuron Model
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/research/Alt-Filter-and-Fire_Neuron_Model_SNN.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/comob-project/snn-sound-localization"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        <a class="edit-button" href="https://github.com/comob-project/snn-sound-localization/edit/main/research/Alt-Filter-and-Fire_Neuron_Model_SNN.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/comob-project/snn-sound-localization/main?urlpath=tree/research/Alt-Filter-and-Fire_Neuron_Model_SNN.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/comob-project/snn-sound-localization/blob/main/research/Alt-Filter-and-Fire_Neuron_Model_SNN.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#background">
   Background
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#experiments-conducted-23-7-23">
     Experiments conducted (23.7.23)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#imports">
   Imports
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hyperparameters">
   Hyperparameters
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#functions">
   Functions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stimulus">
     Stimulus
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#snn">
     SNN
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training">
     Training
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-and-test-performance-of-the-trained-model">
     Train and Test Performance of the Trained Model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#alternative-filter-and-fire-neuron-model">
     Alternative Filter-and-Fire Neuron Model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exp-1-training-testing-results">
   Exp 1. Training &amp; Testing Results
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-no-multiple-connections-m-1">
     Using no multiple connections (M=1)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exp-2-training-testing-results">
   Exp 2. Training &amp; Testing Results
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-multiple-connections-m-3">
     Using multiple connections (M=3)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#results">
   Results
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Filter-and-Fire Neuron Model</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#background">
   Background
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#experiments-conducted-23-7-23">
     Experiments conducted (23.7.23)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#imports">
   Imports
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hyperparameters">
   Hyperparameters
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#functions">
   Functions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stimulus">
     Stimulus
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#snn">
     SNN
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training">
     Training
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-and-test-performance-of-the-trained-model">
     Train and Test Performance of the Trained Model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#alternative-filter-and-fire-neuron-model">
     Alternative Filter-and-Fire Neuron Model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exp-1-training-testing-results">
   Exp 1. Training &amp; Testing Results
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-no-multiple-connections-m-1">
     Using no multiple connections (M=1)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exp-2-training-testing-results">
   Exp 2. Training &amp; Testing Results
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-multiple-connections-m-3">
     Using multiple connections (M=3)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#results">
   Results
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="filter-and-fire-neuron-model">
<h1>Filter-and-Fire Neuron Model<a class="headerlink" href="#filter-and-fire-neuron-model" title="Permalink to this headline">¶</a></h1>
<div class="section" id="background">
<h2>Background<a class="headerlink" href="#background" title="Permalink to this headline">¶</a></h2>
<p>This notebook provide an alternative filter-and-fire pytorch neuron model that might be easier and more robust to use.</p>
<p>In fact, we provide here an implementation of the Exp 3. that was introduced in Filter-and-Fire_Neuron_Model_SNN.ipynb, but wasn’t implemented there.</p>
<div class="section" id="experiments-conducted-23-7-23">
<h3>Experiments conducted (23.7.23)<a class="headerlink" href="#experiments-conducted-23-7-23" title="Permalink to this headline">¶</a></h3>
<p>Note:</p>
<ul class="simple">
<li><p>M: number of connections per presynaptic axon</p></li>
<li><p>Exp 1. M = 1</p></li>
<li><p>Exp 2. M = 3 (Exp 3. of Filter-and-Fire_Neuron_Model_SNN.ipynb)</p></li>
</ul>
</div>
</div>
<div class="section" id="imports">
<h2>Imports<a class="headerlink" href="#imports" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>tqdm

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">signal</span>

<span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span> <span class="k">as</span> <span class="n">pbar</span>

<span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float</span>

<span class="c1"># Check whether a GPU is available</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>     
<span class="k">else</span><span class="p">:</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
    
<span class="n">my_computer_is_slow</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># set this to True if using Colab</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: tqdm in /ems/elsc-labs/segev-i/ido.aizenbud/.local/lib/python3.9/site-packages (4.62.3)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="hyperparameters">
<h2>Hyperparameters<a class="headerlink" href="#hyperparameters" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Constants</span>
<span class="n">SECOND</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">MS</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">HZ</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">PI</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span>
<span class="n">DT</span> <span class="o">=</span> <span class="mi">1</span><span class="o">*</span><span class="n">MS</span> <span class="c1"># large time step to make simulations run faster</span>

<span class="n">ANF_PER_EAR</span> <span class="o">=</span> <span class="mi">100</span>    <span class="c1"># repeats of each ear with independent noise (was 1000 in my other notebooks)</span>
<span class="n">ENVELOPE_POWER</span> <span class="o">=</span> <span class="mi">2</span>   <span class="c1"># higher values make sharper envelopes, easier</span>
<span class="n">RATE_MAX</span> <span class="o">=</span> <span class="mi">600</span><span class="o">*</span><span class="n">HZ</span>   <span class="c1"># maximum Poisson firing rate</span>
<span class="n">F</span> <span class="o">=</span> <span class="mi">20</span><span class="o">*</span><span class="n">HZ</span>           <span class="c1"># stimulus frequency</span>
<span class="n">DURATION</span> <span class="o">=</span> <span class="mf">.1</span><span class="o">*</span><span class="n">SECOND</span> <span class="c1"># stimulus duration</span>
<span class="n">DURATION_STEPS</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">DURATION</span><span class="o">/</span><span class="n">DT</span><span class="p">))</span> <span class="c1"># 100</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">DURATION_STEPS</span><span class="p">)</span><span class="o">*</span><span class="n">DT</span> <span class="c1"># array of times</span>

<span class="c1"># Network</span>
<span class="n">INPUT_SIZE</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">ANF_PER_EAR</span> <span class="c1"># 200 input neurons</span>
<span class="n">NUM_HIDDEN</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">NUM_CLASSES</span> <span class="o">=</span> <span class="mi">180</span><span class="o">//</span><span class="mi">15</span> <span class="c1"># classes at 15 degree increments</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of classes = </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">NUM_CLASSES</span><span class="p">))</span>
<span class="n">TAU</span> <span class="o">=</span> <span class="mi">5</span><span class="o">*</span><span class="n">MS</span> <span class="c1"># this used to be 20 in the SNN Starting Notebook, is now 5 in Quick Start Notebook</span>

<span class="c1"># Training</span>
<span class="n">MY_COMPUTER_IS_SLOW</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">if</span> <span class="n">MY_COMPUTER_IS_SLOW</span><span class="p">:</span>
    <span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">N_TRAINING_BATCHES</span> <span class="o">=</span> <span class="mi">64</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">128</span>
    <span class="n">N_TRAINING_BATCHES</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">N_TESTING_BATCHES</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">NUM_SAMPLES</span> <span class="o">=</span> <span class="n">BATCH_SIZE</span><span class="o">*</span><span class="n">N_TRAINING_BATCHES</span>
<span class="n">BETA</span> <span class="o">=</span> <span class="mi">5</span> <span class="c1"># for Surrogate Gradient Descent</span>
<span class="n">NUM_EPOCHS</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># (takes ~6min/epoch with INPUT_SIZE=200)</span>
<span class="n">LR</span> <span class="o">=</span> <span class="mf">0.0001</span>

<span class="c1"># Filter-and-Fire Neuron Model (Beniaguev et al., 2022)</span>
<span class="n">NUM_AXONS</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">CONNECTIONS_PER_AXON</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">NUM_SYNAPSES</span> <span class="o">=</span> <span class="n">CONNECTIONS_PER_AXON</span> <span class="o">*</span> <span class="n">NUM_AXONS</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of classes = 12
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="functions">
<h2>Functions<a class="headerlink" href="#functions" title="Permalink to this headline">¶</a></h2>
<div class="section" id="stimulus">
<h3>Stimulus<a class="headerlink" href="#stimulus" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">input_signal</span><span class="p">(</span><span class="n">ipd</span><span class="p">,</span> <span class="n">usual_phase_delays</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generate an input signal (spike array) from array of true IPDs</span>
<span class="sd">  </span>
<span class="sd">    Parameters:</span>
<span class="sd">    ipd (array): true IPDs</span>
<span class="sd">  </span>
<span class="sd">    Returns:</span>
<span class="sd">    spikes (array): input signal from true IPDs (spike trains)</span>
<span class="sd">  </span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">num_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ipd</span><span class="p">)</span> <span class="c1"># i.e., NUM_SAMPLES</span>
    <span class="n">phi</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">PI</span><span class="o">*</span><span class="p">(</span><span class="n">F</span><span class="o">*</span><span class="n">T</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">())</span> <span class="c1"># array of phases corresponding to those times with random offset</span>
 
    <span class="c1"># each point in the array will have a different phase based on which ear it is</span>
    <span class="c1"># and its delay</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">DURATION_STEPS</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">ANF_PER_EAR</span><span class="p">))</span>
    
    <span class="c1"># for each ear, we have anf_per_ear different phase delays from to pi/2 so</span>
    <span class="c1"># that the differences between the two ears can cover the full range from -pi/2 to pi/2</span>
    <span class="k">if</span> <span class="n">usual_phase_delays</span><span class="p">:</span> <span class="c1"># Exp 1., Exp 2.a</span>
        <span class="n">phase_delays</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">PI</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">ANF_PER_EAR</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span> <span class="c1"># Exp 2.b, Exp 3.</span>
        <span class="n">phase_delays</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">ANF_PER_EAR</span><span class="p">)</span>

    <span class="c1"># now we set up these theta to implement that. Some numpy vectorisation logic here which looks a little weird,</span>
    <span class="c1"># but implements the idea in the text above.</span>
    <span class="n">theta</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">ANF_PER_EAR</span><span class="p">]</span> <span class="o">=</span> <span class="n">phi</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span><span class="o">+</span><span class="n">phase_delays</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">theta</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">ANF_PER_EAR</span><span class="p">:]</span> <span class="o">=</span> <span class="n">phi</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span><span class="o">+</span><span class="n">phase_delays</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span><span class="o">+</span><span class="n">ipd</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>

    <span class="c1"># now generate Poisson spikes at the given firing rate as in the previous notebook</span>
    <span class="n">spikes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">DURATION_STEPS</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">ANF_PER_EAR</span><span class="p">)</span><span class="o">&lt;</span><span class="n">RATE_MAX</span><span class="o">*</span><span class="n">DT</span><span class="o">*</span><span class="p">(</span><span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">)))</span><span class="o">**</span><span class="n">ENVELOPE_POWER</span>

    <span class="k">return</span> <span class="n">spikes</span>

<span class="c1"># Generate some true IPDs from U(-pi/2, pi/2) and corresponding spike arrays</span>
<span class="k">def</span> <span class="nf">random_ipd_input_signal</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">usual_phase_delays</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generate the training data: true IPDs are in U(-pi/2, pi/2) </span>
<span class="sd">  </span>
<span class="sd">    Parameters:</span>
<span class="sd">    num_samples (int)</span>
<span class="sd">    usual_phase_delays (boolean): flag on the use of usual or null phase delays</span>
<span class="sd">    tensor (boolean): flag on the use of tensor or numpy objects for the objects returned</span>
<span class="sd">  </span>
<span class="sd">    Returns:</span>
<span class="sd">    ipd (array): true IPDs from U(-pi/2, pi/2)</span>
<span class="sd">    spikes (array): input signal corresponding to the true IPDs in the training data</span>
<span class="sd">  </span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">ipd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span><span class="o">*</span><span class="n">PI</span><span class="o">-</span><span class="n">PI</span><span class="o">/</span><span class="mi">2</span> <span class="c1"># uniformly random in (-pi/2, pi/2)</span>
    <span class="c1">#print(ipd)# okay</span>
    <span class="n">spikes</span> <span class="o">=</span> <span class="n">input_signal</span><span class="p">(</span><span class="n">ipd</span><span class="p">,</span> <span class="n">usual_phase_delays</span><span class="p">)</span>
    <span class="c1">#print(spikes) # empty</span>
    
    <span class="k">if</span> <span class="n">tensor</span><span class="p">:</span>
        <span class="n">ipd</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">ipd</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>        
        <span class="n">spikes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">spikes</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="n">ipd</span><span class="p">,</span> <span class="n">spikes</span>


<span class="k">def</span> <span class="nf">discretise</span><span class="p">(</span><span class="n">ipds</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Discretise the ipds in the training data </span>
<span class="sd">  </span>
<span class="sd">    Parameters:</span>
<span class="sd">    ipds (tensor)</span>
<span class="sd">  </span>
<span class="sd">    Returns:</span>
<span class="sd">    tensor</span>
<span class="sd">  </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">((</span><span class="n">ipds</span><span class="o">+</span><span class="n">PI</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="n">NUM_CLASSES</span><span class="o">/</span><span class="n">PI</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span> <span class="c1"># assumes input is tensor</span>

<span class="k">def</span> <span class="nf">continuise</span><span class="p">(</span><span class="n">ipd_indices</span><span class="p">):</span> <span class="c1"># convert indices back to IPD midpoints</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Undo the discretisation of ipds</span>
<span class="sd">  </span>
<span class="sd">    Parameters:</span>
<span class="sd">    ipd_indices (array)</span>
<span class="sd">  </span>
<span class="sd">    Returns:</span>
<span class="sd">    array</span>
<span class="sd">  </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">ipd_indices</span><span class="o">+</span><span class="mf">0.5</span><span class="p">)</span><span class="o">/</span><span class="n">NUM_CLASSES</span><span class="o">*</span><span class="n">PI</span><span class="o">-</span><span class="n">PI</span><span class="o">/</span><span class="mi">2</span>


<span class="c1"># Generator function iterates over the data in batches</span>
<span class="c1"># We randomly permute the order of the data to improve learning</span>
<span class="k">def</span> <span class="nf">data_generator</span><span class="p">(</span><span class="n">ipds</span><span class="p">,</span> <span class="n">spikes</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generate the whole training data by iterating over the data in the batches.</span>
<span class="sd">    Order of the data is randomly permuted to improve learning.</span>
<span class="sd">  </span>
<span class="sd">    Parameters:</span>
<span class="sd">    ipds (tensor)</span>
<span class="sd">    spikes (tensor): flag on the use of usual or null phase delays</span>
<span class="sd">  </span>
<span class="sd">    Yields:</span>
<span class="sd">    x_local (tensor): relates to the spikes</span>
<span class="sd">    y_local (tensor): relates to the ipds</span>
<span class="sd">  </span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">perm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">spikes</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">spikes</span> <span class="o">=</span> <span class="n">spikes</span><span class="p">[</span><span class="n">perm</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
    <span class="n">ipds</span> <span class="o">=</span> <span class="n">ipds</span><span class="p">[</span><span class="n">perm</span><span class="p">]</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">spikes</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">n_batch</span> <span class="o">=</span> <span class="n">n</span><span class="o">//</span><span class="n">BATCH_SIZE</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_batch</span><span class="p">):</span>
        <span class="n">x_local</span> <span class="o">=</span> <span class="n">spikes</span><span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="n">BATCH_SIZE</span><span class="p">:(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
        <span class="n">y_local</span> <span class="o">=</span> <span class="n">ipds</span><span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="n">BATCH_SIZE</span><span class="p">:(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">BATCH_SIZE</span><span class="p">]</span>
        
        <span class="k">yield</span> <span class="n">x_local</span><span class="p">,</span> <span class="n">y_local</span>

<span class="c1"># Plot a few just to show how it looks</span>
<span class="k">def</span> <span class="nf">plot_some_input_examples</span><span class="p">(</span><span class="n">num_examples</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plots some example inputs.</span>
<span class="sd">  </span>
<span class="sd">    Parameters:</span>
<span class="sd">    num_examples (int): default = 8</span>
<span class="sd">  </span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">ipd</span><span class="p">,</span> <span class="n">spikes</span> <span class="o">=</span> <span class="n">random_ipd_input_signal</span><span class="p">(</span><span class="n">num_examples</span><span class="p">)</span>
    <span class="n">spikes</span> <span class="o">=</span> <span class="n">spikes</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_examples</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">spikes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">gray_r</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;True IPD = </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">ipd</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="mi">180</span><span class="o">/</span><span class="n">PI</span><span class="p">)</span><span class="si">}</span><span class="s1"> deg&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">i</span><span class="o">&gt;=</span><span class="mi">4</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time (steps)&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">i</span><span class="o">%</span><span class="k">4</span>==0:
            <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Input neuron index&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    
    
<span class="n">plot_some_input_examples</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Alt-Filter-and-Fire_Neuron_Model_SNN_10_0.png" src="../_images/Alt-Filter-and-Fire_Neuron_Model_SNN_10_0.png" />
</div>
</div>
</div>
<div class="section" id="snn">
<h3>SNN<a class="headerlink" href="#snn" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SurrGradSpike</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Function</span><span class="p">):</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">save_for_backward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="n">out</span><span class="p">[</span><span class="nb">input</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="k">return</span> <span class="n">out</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">):</span>
        <span class="nb">input</span><span class="p">,</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">saved_tensors</span>
        <span class="c1"># Original SPyTorch/SuperSpike gradient</span>
        <span class="c1"># This seems to be a typo or error? But it works well</span>
        <span class="c1">#grad = grad_output/(100*torch.abs(input)+1.0)**2</span>
        <span class="c1"># Sigmoid</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">grad_output</span><span class="o">*</span><span class="n">BETA</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">BETA</span><span class="o">*</span><span class="nb">input</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">BETA</span><span class="o">*</span><span class="nb">input</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">grad</span>

<span class="n">spike_fn</span>  <span class="o">=</span> <span class="n">SurrGradSpike</span><span class="o">.</span><span class="n">apply</span>

<span class="c1"># Run the simulation</span>
<span class="k">def</span> <span class="nf">snn</span><span class="p">(</span><span class="n">presynaptic_input_spikes_tensor</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">W1_bis</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> 
        <span class="n">multiple_connections_per_axon</span><span class="p">,</span> <span class="n">single_neuron_model</span><span class="p">):</span>
<span class="w">    </span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Runs the SNN simulation.</span>
<span class="sd">  </span>
<span class="sd">    Parameters:</span>
<span class="sd">    presynaptic_input_spikes_tensor (tensor): corresponds to x_local in the training</span>
<span class="sd">    W1 (tensor): initialised trainable weight parameter for the first layer</span>
<span class="sd">    W2 (tensor): initialised trainable weight parameter for the second layer</span>
<span class="sd">    multiple_connections_per_axon (boolean): flag on the use of multiple connections per axon,</span>
<span class="sd">    single_neuron_model (function): a function that computes the output of a single neuron, given input over multiple segments</span>
<span class="sd">  </span>
<span class="sd">    Returns:</span>
<span class="sd">    v_rec (tensor): recorded membrane potential of output</span>
<span class="sd">    input_smoothed (tensor): smoothed inputs</span>
<span class="sd">  </span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="c1"># First layer: input to hidden</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">NUM_HIDDEN</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">NUM_HIDDEN</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">s_rec</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span><span class="p">]</span>

    <span class="n">cur_connections_per_axon</span> <span class="o">=</span> <span class="n">CONNECTIONS_PER_AXON</span> <span class="k">if</span> <span class="n">multiple_connections_per_axon</span> <span class="k">else</span> <span class="mi">1</span>

    <span class="n">inputs_for_all_segments_of_all_hidden</span> <span class="o">=</span> <span class="p">(</span><span class="n">presynaptic_input_spikes_tensor</span> <span class="o">@</span> <span class="n">W1</span><span class="p">)</span>

    <span class="c1"># BATCH_SIZE, DURATION_STEPS, NUM_HIDDEN * cur_connections_per_axon</span>

    <span class="n">inputs_for_all_segments_of_all_hidden</span> <span class="o">=</span> <span class="n">inputs_for_all_segments_of_all_hidden</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># BATCH_SIZE, NUM_HIDDEN * cur_connections_per_axon, DURATION_STEPS</span>

    <span class="n">inputs_for_all_segments_of_all_hidden_for_single_neuron</span> <span class="o">=</span> <span class="n">inputs_for_all_segments_of_all_hidden</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">BATCH_SIZE</span> <span class="o">*</span> <span class="n">NUM_HIDDEN</span><span class="p">,</span> <span class="n">cur_connections_per_axon</span><span class="p">,</span> <span class="n">DURATION_STEPS</span><span class="p">)</span>

    <span class="c1"># BATCH_SIZE * NUM_HIDDEN, cur_connections_per_axon, DURATION_STEPS</span>

    <span class="c1"># we use a handy trick here, enlarging the batch size, so we can use a single neuron model for all the neurons in the hidden layer</span>
    <span class="n">hidden_output</span> <span class="o">=</span> <span class="n">single_neuron_model</span><span class="p">(</span><span class="n">inputs_for_all_segments_of_all_hidden_for_single_neuron</span><span class="p">)</span>

    <span class="c1"># BATCH_SIZE * NUM_HIDDEN, DURATION_STEPS</span>

    <span class="n">hidden_output</span> <span class="o">=</span> <span class="n">hidden_output</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">NUM_HIDDEN</span><span class="p">,</span> <span class="n">DURATION_STEPS</span><span class="p">)</span>
    
    <span class="n">s_rec</span> <span class="o">=</span> <span class="n">hidden_output</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># Second layer: hidden to output</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">NUM_CLASSES</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">NUM_CLASSES</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">v_rec</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="p">]</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;abc,cd-&gt;abd&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">s_rec</span><span class="p">,</span> <span class="n">W2</span><span class="p">))</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">DT</span><span class="o">/</span><span class="n">TAU</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">DURATION_STEPS</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>  
        <span class="n">v</span> <span class="o">=</span> <span class="n">alpha</span><span class="o">*</span><span class="n">v</span> <span class="o">+</span> <span class="n">h</span><span class="p">[:,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">v_rec</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="n">v_rec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">v_rec</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Return recorded membrane potential of output and smoothed input (for visualisation)</span>
    <span class="k">return</span> <span class="n">v_rec</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="training">
<h3>Training<a class="headerlink" href="#training" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Weights and uniform weight initialisation</span>
<span class="k">def</span> <span class="nf">init_weight_matrix</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialises the weight matrix used in the fanin-fanout calculations for the initialisation of W1 and W2.</span>
<span class="sd">  </span>
<span class="sd">    Parameters:</span>
<span class="sd">    None</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    W (tensor): weight tensor used in fanin-fanout calculations</span>
<span class="sd">  </span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">W</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">INPUT_SIZE</span><span class="p">,</span> <span class="n">NUM_CLASSES</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    <span class="n">fan_in</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">_calculate_fan_in_and_fan_out</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>
    <span class="n">bound</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">fan_in</span><span class="p">)</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="o">-</span><span class="n">bound</span><span class="p">,</span> <span class="n">bound</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">W</span>

<span class="k">def</span> <span class="nf">init_weight_matrices</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">multiple_connections_per_axon</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialises the weight matrices in the SNN: W1, W1_bis and W2.</span>
<span class="sd">  </span>
<span class="sd">    Parameters:</span>
<span class="sd">    W (tensor): weight tensor used in fanin-fanout calculations for W1 and W2</span>
<span class="sd">    multiple_connections_per_axon (boolean): flag on the use of multiple connections per axon</span>
<span class="sd">  </span>
<span class="sd">    Returns:</span>
<span class="sd">    W1 (tensor): initialised trainable weight parameter for the first layer</span>
<span class="sd">    W1_bis (tensor): fixed non-trainable weight parameter for the first layer when there are multiple connections per axon</span>
<span class="sd">    W2 (tensor): initialised trainable weight parameter for the second layer</span>
<span class="sd">  </span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">if</span> <span class="n">multiple_connections_per_axon</span><span class="p">:</span> <span class="c1"># Exp. 3</span>
        <span class="c1"># Input to hidden layer</span>
        <span class="n">W1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">INPUT_SIZE</span><span class="p">,</span> <span class="n">NUM_HIDDEN</span><span class="o">*</span><span class="n">CONNECTIONS_PER_AXON</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
        <span class="n">fan_in</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">_calculate_fan_in_and_fan_out</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>
        <span class="n">bound</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">fan_in</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="o">-</span><span class="n">bound</span><span class="p">,</span> <span class="n">bound</span><span class="p">)</span>
    
        <span class="c1"># placeholder for W1_bis (not used)</span>
        <span class="n">W1_bis</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">NUM_HIDDEN</span><span class="o">*</span><span class="n">CONNECTIONS_PER_AXON</span><span class="p">,</span> <span class="n">NUM_HIDDEN</span><span class="p">)</span>
    
        <span class="c1"># Hidden layer to output</span>
        <span class="n">W2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">NUM_HIDDEN</span><span class="p">,</span> <span class="n">NUM_CLASSES</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
        <span class="n">fan_in</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">_calculate_fan_in_and_fan_out</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>
        <span class="n">bound</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">fan_in</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="n">W2</span><span class="p">,</span> <span class="o">-</span><span class="n">bound</span><span class="p">,</span> <span class="n">bound</span><span class="p">)</span>
        
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Input to hidden layer</span>
        <span class="n">W1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">INPUT_SIZE</span><span class="p">,</span> <span class="n">NUM_HIDDEN</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
        <span class="n">fan_in</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">_calculate_fan_in_and_fan_out</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>
        <span class="n">bound</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">fan_in</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="o">-</span><span class="n">bound</span><span class="p">,</span> <span class="n">bound</span><span class="p">)</span>
        
        <span class="c1"># placeholder for W1_bis (not used)</span>
        <span class="n">W1_bis</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">NUM_HIDDEN</span><span class="o">*</span><span class="n">CONNECTIONS_PER_AXON</span><span class="p">,</span> <span class="n">NUM_HIDDEN</span><span class="p">)</span>
    
        <span class="c1"># Hidden layer to output</span>
        <span class="n">W2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">NUM_HIDDEN</span><span class="p">,</span> <span class="n">NUM_CLASSES</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
        <span class="n">fan_in</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">_calculate_fan_in_and_fan_out</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>
        <span class="n">bound</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">fan_in</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="n">W2</span><span class="p">,</span> <span class="o">-</span><span class="n">bound</span><span class="p">,</span> <span class="n">bound</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="n">W1</span><span class="p">,</span> <span class="n">W1_bis</span><span class="p">,</span> <span class="n">W2</span>
    
    
<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">ipds</span><span class="p">,</span> <span class="n">spikes</span><span class="p">,</span> <span class="n">usual_phase_delays</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">multiple_connections_per_axon</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_tau_constants</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">minimal_smoothing</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Runs the training of the SNN simulation.</span>
<span class="sd">  </span>
<span class="sd">    Parameters:</span>
<span class="sd">    usual_phase_delays (boolean): flag on the use of usual or null phase delays</span>
<span class="sd">    multiple_connections_per_axon (boolean): flag on the use of multiple connections per axon</span>
<span class="sd">    random_tau_constants (boolean): flag on the use of randomly sampled tau hyperparameters (rise and decay)</span>
<span class="sd">    minimal_smoothing (boolean): flag on the use of fast tau hyperparameters for minimal input spike smoothing</span>
<span class="sd">  </span>
<span class="sd">    Returns:</span>
<span class="sd">    ipds (tensor): training data (y)</span>
<span class="sd">    spikes (tensor): training data (X)</span>
<span class="sd">    W1 (tensor): trained W1</span>
<span class="sd">    W2 (tensor): trained W2</span>
<span class="sd">    snn_training_snapshot (list): snapshots of the training at each epoch</span>
<span class="sd">  </span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="c1"># Generate the training data</span>
    <span class="c1">#ipds, spikes = random_ipd_input_signal(NUM_SAMPLES, usual_phase_delays)</span>
    
    <span class="c1"># Initialise weight matrices</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">init_weight_matrix</span><span class="p">()</span> <span class="c1"># for fan_in/out calculations</span>
    <span class="n">W1</span><span class="p">,</span> <span class="n">W1_bis</span><span class="p">,</span> <span class="n">W2</span> <span class="o">=</span> <span class="n">init_weight_matrices</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">multiple_connections_per_axon</span><span class="p">)</span>

    <span class="c1"># Optimiser and loss function</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">([</span><span class="n">W1</span><span class="p">,</span> <span class="n">W2</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="n">LR</span><span class="p">)</span>
    <span class="n">log_softmax_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>

    <span class="n">loss_hist</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">snn_training_snapshot</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># TODO: plug all of these parameters inside: random_tau_constants, minimal_smoothing, currently they are being ignored</span>
    <span class="n">single_neuron_model</span> <span class="o">=</span> <span class="n">FilterAndFireNeuron</span><span class="p">(</span><span class="n">count_segments</span><span class="o">=</span><span class="n">CONNECTIONS_PER_AXON</span> <span class="k">if</span> <span class="n">multiple_connections_per_axon</span> <span class="k">else</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">NUM_EPOCHS</span><span class="p">)):</span>
        
        <span class="n">local_loss</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">batch_number</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--------------------------------------------------------&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;EPOCH </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">e</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
        
        <span class="k">for</span> <span class="n">x_local</span><span class="p">,</span> <span class="n">y_local</span> <span class="ow">in</span> <span class="n">data_generator</span><span class="p">(</span><span class="n">discretise</span><span class="p">(</span><span class="n">ipds</span><span class="p">),</span> <span class="n">spikes</span><span class="p">):</span>
            
            <span class="n">batch_number</span> <span class="o">+=</span> <span class="mi">1</span>
            
            <span class="c1"># Run network</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">snn</span><span class="p">(</span><span class="n">x_local</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">W1_bis</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">multiple_connections_per_axon</span><span class="p">,</span> <span class="n">single_neuron_model</span><span class="p">)</span>
            
            <span class="c1"># Compute cross entropy loss</span>
            <span class="c1">#m = torch.sum(output, 1)*0.01  # Sum time dimension</span>
            <span class="c1"># Compute cross entropy loss</span>
            <span class="n">m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Mean across time dimension</span>

            <span class="n">reg</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># to add regularisation later if wanted</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">log_softmax_fn</span><span class="p">(</span><span class="n">m</span><span class="p">),</span> <span class="n">y_local</span><span class="p">)</span> <span class="o">+</span> <span class="n">reg</span>
            <span class="n">local_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

            <span class="c1"># Update gradients</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="c1"># Record and print the loss of the current epoch</span>
        <span class="n">loss_hist</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">local_loss</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---EPOCH </span><span class="si">%i</span><span class="s2">: LOSS=</span><span class="si">%.5f</span><span class="s2">&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">e</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">local_loss</span><span class="p">)))</span>

        <span class="c1"># Plot raster plot: </span>
        <span class="c1"># e.g. input_smoothed for the 1st example of the last batch of the current epoch</span>
        <span class="c1">#print(&quot;---Raster Plots at Epoch {} - Example #1/64 of the Last Batch Group&quot;.format(e+1))</span>
        <span class="c1">#plt.figure(1)</span>
        <span class="c1">#plt.title(&quot;input_smoothed example vs corresponding initial spike train&quot;)</span>
        <span class="c1">#plt.subplot(211)</span>
        <span class="c1">#plt.imshow(input_smoothed[0, :, :].detach().numpy().T, aspect=&#39;auto&#39;, interpolation=&#39;nearest&#39;, cmap=plt.cm.gray_r)</span>
        <span class="c1">#plt.xlabel(&#39;Time (steps)&#39;)</span>
        <span class="c1">#plt.ylabel(&#39;Input neuron index&#39;)</span>
        <span class="c1">#plt.subplot(212)</span>
        <span class="c1">#plt.imshow(x_local[0, :, :].detach().numpy().T, aspect=&#39;auto&#39;, interpolation=&#39;nearest&#39;, cmap=plt.cm.gray_r)</span>
        <span class="c1">#plt.xlabel(&#39;Time (steps)&#39;)</span>
        <span class="c1">#plt.ylabel(&#39;Input neuron index&#39;)</span>
    
        <span class="c1">#plt.show()</span>
        
        <span class="c1"># Take a snapshot of the model at the end of the current epoch. </span>
        <span class="c1">## Use cases:</span>
        <span class="c1">### if we want to resume training from this current epoch,</span>
        <span class="c1">### or if the training is halted before the last epoch</span>
        <span class="n">snn_training_snapshot</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s1">&#39;W1&#39;</span><span class="p">:</span><span class="n">W1</span><span class="p">,</span> <span class="s1">&#39;W2&#39;</span><span class="p">:</span><span class="n">W2</span><span class="p">,</span> 
                                      <span class="s1">&#39;multiple_connections_per_axon&#39;</span><span class="p">:</span><span class="n">multiple_connections_per_axon</span><span class="p">,</span> 
                                      <span class="s1">&#39;random_tau_constants&#39;</span><span class="p">:</span><span class="n">random_tau_constants</span><span class="p">,</span> 
                                      <span class="s1">&#39;minimal_smoothing&#39;</span><span class="p">:</span><span class="n">minimal_smoothing</span><span class="p">})</span> 
        
    <span class="c1"># Plot the loss function over time</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss_hist</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

    <span class="c1"># return the train dataset (ipds, spikes) and trained weights for analysis</span>
    <span class="c1"># also return the list of model snapshots for each epoch (in case we want to resume training)</span>
    <span class="k">return</span> <span class="n">W1</span><span class="p">,</span> <span class="n">W1_bis</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">snn_training_snapshot</span><span class="p">,</span> <span class="n">single_neuron_model</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="train-and-test-performance-of-the-trained-model">
<h3>Train and Test Performance of the Trained Model<a class="headerlink" href="#train-and-test-performance-of-the-trained-model" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_accuracy</span><span class="p">(</span><span class="n">ipds</span><span class="p">,</span> <span class="n">spikes</span><span class="p">,</span> <span class="n">run</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Gets the accuracy on data (train or test)</span>
<span class="sd">  </span>
<span class="sd">    Parameters:</span>
<span class="sd">    ipds (tensor)</span>
<span class="sd">    spikes (tensor)</span>
<span class="sd">    run (lambda function)</span>
<span class="sd">  </span>
<span class="sd">    Returns:</span>
<span class="sd">    ipd_true (list)</span>
<span class="sd">    ipd_est (list)</span>
<span class="sd">    confusion (numpy array)</span>
<span class="sd">    accs (list)</span>
<span class="sd">  </span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">accs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">ipd_true</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">ipd_est</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">confusion</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">NUM_CLASSES</span><span class="p">,</span> <span class="n">NUM_CLASSES</span><span class="p">))</span>
    
    <span class="c1">#print(ipds.shape)</span>
    <span class="c1">#print(spikes.shape)</span>
    
    <span class="k">for</span> <span class="n">x_local</span><span class="p">,</span> <span class="n">y_local</span> <span class="ow">in</span> <span class="n">data_generator</span><span class="p">(</span><span class="n">ipds</span><span class="p">,</span> <span class="n">spikes</span><span class="p">):</span>
        <span class="n">y_local_orig</span> <span class="o">=</span> <span class="n">y_local</span>
        <span class="n">y_local</span> <span class="o">=</span> <span class="n">discretise</span><span class="p">(</span><span class="n">y_local</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">run</span><span class="p">(</span><span class="n">x_local</span><span class="p">)</span>
        <span class="c1">#m = torch.sum(output, 1)  # Sum time dimension</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">am</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># argmax over output units</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_local</span> <span class="o">==</span> <span class="n">am</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>  <span class="c1"># compare to labels</span>
        
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">y_local</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">am</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()):</span>
            <span class="n">confusion</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
            
        <span class="n">ipd_true</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_local_orig</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        <span class="n">ipd_est</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">continuise</span><span class="p">(</span><span class="n">am</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>
        <span class="n">accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span>

    <span class="n">ipd_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">ipd_true</span><span class="p">)</span>
    <span class="n">ipd_est</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">ipd_est</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">ipd_true</span><span class="p">,</span> <span class="n">ipd_est</span><span class="p">,</span> <span class="n">confusion</span><span class="p">,</span> <span class="n">accs</span>

<span class="k">def</span> <span class="nf">report_accuracy</span><span class="p">(</span><span class="n">ipd_true</span><span class="p">,</span> <span class="n">ipd_est</span><span class="p">,</span> <span class="n">confusion</span><span class="p">,</span> <span class="n">accs</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plots the accuracy on data (train or test).</span>
<span class="sd">  </span>
<span class="sd">    Parameters:</span>
<span class="sd">    ipd_true (list)</span>
<span class="sd">    ipd_est (list)</span>
<span class="sd">    confusion (numpy array)</span>
<span class="sd">    accs (list)</span>
<span class="sd">    label (string): &quot;Test&quot; or &quot;Train&quot;</span>
<span class="sd">  </span>
<span class="sd">    Returns:</span>
<span class="sd">    None</span>
<span class="sd">  </span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">abs_errors_deg</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">ipd_true</span><span class="o">-</span><span class="n">ipd_est</span><span class="p">)</span><span class="o">*</span><span class="mi">180</span><span class="o">/</span><span class="n">PI</span>

    <span class="nb">print</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s2"> classifier accuracy: </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">accs</span><span class="p">)</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s2"> absolute error: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">abs_errors_deg</span><span class="p">)</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> deg&quot;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">ipd_true</span> <span class="o">*</span> <span class="mi">180</span> <span class="o">/</span> <span class="n">PI</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">NUM_CLASSES</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;True&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">ipd_est</span> <span class="o">*</span> <span class="mi">180</span> <span class="o">/</span> <span class="n">PI</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">NUM_CLASSES</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Estimated&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;IPD&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
    <span class="n">confusion</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">confusion</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">confusion</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s1">&#39;equal&#39;</span><span class="p">,</span> <span class="n">origin</span><span class="o">=</span><span class="s1">&#39;lower&#39;</span><span class="p">,</span> <span class="n">extent</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">90</span><span class="p">,</span> <span class="mi">90</span><span class="p">,</span> <span class="o">-</span><span class="mi">90</span><span class="p">,</span> <span class="mi">90</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;True IPD&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Estimated IPD&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Confusion matrix&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>    

<span class="k">def</span> <span class="nf">analyse_accuracy</span><span class="p">(</span><span class="n">ipds</span><span class="p">,</span> <span class="n">spikes</span><span class="p">,</span> <span class="n">W1_trained</span><span class="p">,</span> <span class="n">W1_bis</span><span class="p">,</span> <span class="n">W2_trained</span><span class="p">,</span> <span class="n">multiple_connections_per_axon</span><span class="p">,</span> <span class="n">single_neuron_model</span><span class="p">,</span> <span class="n">test_data</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Analyses the accuracy on data (train or test)</span>
<span class="sd">  </span>
<span class="sd">    Parameters:</span>
<span class="sd">    ipds_train (tensor)</span>
<span class="sd">    spikes_train (tensor)</span>
<span class="sd">    W1_trained (tensor): trained W1</span>
<span class="sd">    W2_trained (tensor): trained W2</span>
<span class="sd">    multiple_connections_per_axon (boolean): flag on the use of multiple connections per axon</span>
<span class="sd">    random_tau_constants (boolean): flag on the use of randomly sampled tau hyperparameters (rise and decay)</span>
<span class="sd">    minimal_smoothing (boolean): flag on the use of fast tau hyperparameters for minimal input spike smoothing</span>
<span class="sd">    test_data (boolean): flag on the use of test data for the analysis of the accuracy</span>
<span class="sd">  </span>
<span class="sd">    Returns:</span>
<span class="sd">    ipd_true (list)</span>
<span class="sd">    ipd_est (list)</span>
<span class="sd">    confusion (numpy array)</span>
<span class="sd">    accs (list)</span>
<span class="sd">  </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">run_function</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">snn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W1_trained</span><span class="p">,</span> <span class="n">W1_bis</span><span class="p">,</span> <span class="n">W2_trained</span><span class="p">,</span> <span class="n">multiple_connections_per_axon</span><span class="p">,</span> <span class="n">single_neuron_model</span><span class="p">)</span>
    
    <span class="n">ipd_true</span><span class="p">,</span> <span class="n">ipd_est</span><span class="p">,</span> <span class="n">confusion</span><span class="p">,</span> <span class="n">accs</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">ipds</span><span class="p">,</span> <span class="n">spikes</span><span class="p">,</span> <span class="n">run_function</span><span class="p">)</span>
    
    <span class="c1"># Analyse test accuracy</span>
    <span class="k">if</span> <span class="n">test_data</span><span class="p">:</span> 
        <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;Test&quot;</span>
    <span class="c1"># Analyse train accuracy</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;Train&quot;</span>

    <span class="n">report_accuracy</span><span class="p">(</span><span class="n">ipd_true</span><span class="p">,</span> <span class="n">ipd_est</span><span class="p">,</span> <span class="n">confusion</span><span class="p">,</span> <span class="n">accs</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>

    <span class="k">return</span> <span class="mi">100</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">accs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="alternative-filter-and-fire-neuron-model">
<h3>Alternative Filter-and-Fire Neuron Model<a class="headerlink" href="#alternative-filter-and-fire-neuron-model" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_psp_filter</span><span class="p">(</span><span class="n">temporal_length</span><span class="p">,</span> <span class="n">tau_rise</span><span class="p">,</span> <span class="n">tau_decay</span><span class="p">):</span>
    <span class="n">safety_factor</span> <span class="o">=</span> <span class="mf">1.5</span>
    <span class="k">if</span> <span class="n">tau_rise</span> <span class="o">&gt;=</span> <span class="p">(</span><span class="n">tau_decay</span> <span class="o">/</span> <span class="n">safety_factor</span><span class="p">):</span>
        <span class="n">tau_decay</span> <span class="o">=</span> <span class="n">safety_factor</span> <span class="o">*</span> <span class="n">tau_rise</span>

    <span class="n">exp_r</span> <span class="o">=</span> <span class="n">signal</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="n">temporal_length</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">tau_rise</span><span class="p">,</span> <span class="n">sym</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">exp_d</span> <span class="o">=</span> <span class="n">signal</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="n">temporal_length</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">tau_decay</span><span class="p">,</span> <span class="n">sym</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">post_syn_potential</span> <span class="o">=</span> <span class="n">exp_d</span> <span class="o">-</span> <span class="n">exp_r</span>
    <span class="n">post_syn_potential</span> <span class="o">=</span> <span class="n">post_syn_potential</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">post_syn_potential</span><span class="p">)</span>
    <span class="n">post_syn_potential</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flipud</span><span class="p">(</span><span class="n">post_syn_potential</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">post_syn_potential</span>

<span class="k">class</span> <span class="nc">PostSynapticPotentials</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tau_rise_vec</span><span class="p">,</span> <span class="n">tau_decay_vec</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">count_filters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tau_rise_vec</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tau_rise_vec</span> <span class="o">=</span> <span class="n">tau_rise_vec</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tau_decay_vec</span> <span class="o">=</span> <span class="n">tau_decay_vec</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temporal_filter_length</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">tau_decay_vec</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="n">temporal_filters</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">count_filters</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">temporal_filter_length</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">count_filters</span><span class="p">):</span>
            <span class="n">temporal_filters</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                <span class="n">create_psp_filter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">temporal_filter_length</span><span class="p">,</span> <span class="n">tau_rise_vec</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                 <span class="n">tau_decay_vec</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">temporal_filters</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">temporal_filters</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># 0 batch size, 1 channel_shape, 2 time</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">x_time</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">x_channel_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">x_channel_dim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">x_channel_shape</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_channel_shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># TODO: implement one day</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The input tensor must be 3 dimensional.&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">x_channel_dim</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">count_filters</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The number of channels in the input tensor does not match the number of filters.&#39;</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">x_channel_dim</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">temporal_filter_length</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">x</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">filtered</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">conv1d</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">temporal_filters</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">temporal_filter_length</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">count_filters</span><span class="p">)[:,:,</span><span class="bp">self</span><span class="o">.</span><span class="n">temporal_filter_length</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">temporal_filter_length</span><span class="p">]</span>
        <span class="n">filtered</span> <span class="o">=</span> <span class="n">filtered</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">x_channel_dim</span><span class="p">,</span> <span class="n">x_time</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">filtered</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">FilterAndFireNeuron</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">count_segments</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">tau_rise_range</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">],</span> <span class="n">tau_decay_range</span><span class="o">=</span><span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">30</span><span class="p">],</span>
                 <span class="n">sort_tau_rise</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sort_tau_decay</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">tau_rise_vec</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tau_decay_vec</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">return_currents</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_voltage</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">count_axons</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">tau_rise_vec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">tau_decay_vec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tau_rise_vec</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tau_decay_vec</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;tau_rise_vec and tau_decay_vec must have the same length.&#39;</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">count_segments</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tau_rise_vec</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">count_axons</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">effective_tau_rise_vec</span> <span class="o">=</span> <span class="n">tau_rise_vec</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">effective_tau_decay_vec</span> <span class="o">=</span> <span class="n">tau_decay_vec</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">psps</span> <span class="o">=</span> <span class="n">PostSynapticPotentials</span><span class="p">(</span><span class="n">tau_rise_vec</span><span class="p">,</span> <span class="n">tau_decay_vec</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">count_synapses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">count_axons</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">count_segments</span>

        <span class="k">elif</span> <span class="n">tau_rise_range</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">tau_decay_range</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">count_segments</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">count_segments</span> <span class="o">=</span> <span class="n">count_segments</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">count_synapses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">count_axons</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">count_segments</span>

            <span class="c1"># repeat the same filter for each axon</span>
            <span class="n">tau_rise_vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">tau_rise_range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tau_rise_range</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">count_synapses</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">sort_tau_rise</span><span class="p">:</span>
                <span class="c1"># sort the tau_rise_vec to make sure that the first element is the largest</span>
                <span class="n">tau_rise_vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">tau_rise_vec</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

            <span class="n">tau_decay_vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">tau_decay_range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tau_decay_range</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">count_synapses</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">sort_tau_decay</span><span class="p">:</span>
                <span class="c1"># sort the tau_decay_vec to make sure that the first element is the largest</span>
                <span class="n">tau_decay_vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">tau_decay_vec</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">effective_tau_rise_vec</span> <span class="o">=</span> <span class="n">tau_rise_vec</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">effective_tau_decay_vec</span> <span class="o">=</span> <span class="n">tau_decay_vec</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">psps</span> <span class="o">=</span> <span class="n">PostSynapticPotentials</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">effective_tau_rise_vec</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">effective_tau_decay_vec</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Either tau_rise_vec and tau_decay_vec or tau_rise_range and tau_decay_range and count_segments must be specified.&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">return_currents</span> <span class="o">=</span> <span class="n">return_currents</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_voltage</span> <span class="o">=</span> <span class="n">return_voltage</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">x_time</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">x_channel_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">x_channel_dim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">x_channel_shape</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">x_channel_dim</span><span class="p">,</span> <span class="n">x_time</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">x_channel_dim</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">count_segments</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The number of channels does not match the number of segments.&#39;</span><span class="p">)</span>

        <span class="n">currents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">psps</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_currents</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">currents</span>            

        <span class="c1"># sum over synapses</span>
        <span class="n">somatic_current</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">currents</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># a naive approach for now (might want to have a resting membrane potential and a resistance)</span>
        <span class="n">somatic_voltage</span> <span class="o">=</span> <span class="n">somatic_current</span>

        <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">somatic_voltage</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">s</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">somatic_voltage</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

        <span class="n">alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">DT</span><span class="o">/</span><span class="n">TAU</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">DURATION_STEPS</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">v</span><span class="p">[:,</span> <span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">alpha</span><span class="o">*</span><span class="n">v</span><span class="p">[:,</span> <span class="n">t</span><span class="p">]</span> <span class="o">+</span> <span class="n">somatic_voltage</span><span class="p">[:,</span> <span class="n">t</span><span class="p">])</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">s</span><span class="p">[:,</span> <span class="n">t</span><span class="p">])</span> <span class="c1"># multiply by 0 after a spike (similar to soma_current) </span>
            <span class="n">s</span><span class="p">[:,</span> <span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">spike_fn</span><span class="p">(</span><span class="n">v</span><span class="p">[:,</span> <span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># threshold of 1</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_voltage</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">v</span>

        <span class="k">return</span> <span class="n">s</span>
    
    <span class="k">def</span> <span class="nf">get_model_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">count_segments</span><span class="p">,),</span> <span class="kc">True</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Note: if the network performs at chance, the accuracy should be 1 out of 12 (since there are 12 classes).</p>
</div>
</div>
<div class="section" id="exp-1-training-testing-results">
<h2>Exp 1. Training &amp; Testing Results<a class="headerlink" href="#exp-1-training-testing-results" title="Permalink to this headline">¶</a></h2>
<div class="section" id="using-no-multiple-connections-m-1">
<h3>Using no multiple connections (M=1)<a class="headerlink" href="#using-no-multiple-connections-m-1" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># training</span>
<span class="c1"># Generate the training data</span>
<span class="n">ipds_train</span><span class="p">,</span> <span class="n">spikes_train</span> <span class="o">=</span> <span class="n">random_ipd_input_signal</span><span class="p">(</span><span class="n">NUM_SAMPLES</span><span class="p">,</span> <span class="n">usual_phase_delays</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">Exp1_W1_trained</span><span class="p">,</span> <span class="n">W1_bis</span><span class="p">,</span> <span class="n">Exp1_W2_trained</span><span class="p">,</span> <span class="n">Exp1_snn_training_snapshot</span><span class="p">,</span> <span class="n">single_neuron_model</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">ipds_train</span><span class="p">,</span> <span class="n">spikes_train</span><span class="p">,</span>
                                                                                         <span class="n">multiple_connections_per_axon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/100 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--------------------------------------------------------
EPOCH 1
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1%|          | 1/100 [00:06&lt;10:45,  6.52s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 1: LOSS=2.80819
--------------------------------------------------------
EPOCH 2
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  2%|▏         | 2/100 [00:13&lt;10:42,  6.55s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 2: LOSS=2.56571
--------------------------------------------------------
EPOCH 3
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  3%|▎         | 3/100 [00:19&lt;10:44,  6.65s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 3: LOSS=2.46367
--------------------------------------------------------
EPOCH 4
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  4%|▍         | 4/100 [00:27&lt;10:59,  6.87s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 4: LOSS=2.39239
--------------------------------------------------------
EPOCH 5
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  5%|▌         | 5/100 [00:34&lt;10:55,  6.90s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 5: LOSS=2.34705
--------------------------------------------------------
EPOCH 6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  6%|▌         | 6/100 [00:40&lt;10:35,  6.76s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 6: LOSS=2.30928
--------------------------------------------------------
EPOCH 7
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  7%|▋         | 7/100 [00:47&lt;10:28,  6.76s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 7: LOSS=2.27508
--------------------------------------------------------
EPOCH 8
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  8%|▊         | 8/100 [00:53&lt;10:11,  6.64s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 8: LOSS=2.24177
--------------------------------------------------------
EPOCH 9
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  9%|▉         | 9/100 [01:00&lt;10:11,  6.72s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 9: LOSS=2.21162
--------------------------------------------------------
EPOCH 10
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 10%|█         | 10/100 [01:08&lt;10:30,  7.01s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 10: LOSS=2.18304
--------------------------------------------------------
EPOCH 11
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 11%|█         | 11/100 [01:15&lt;10:20,  6.98s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 11: LOSS=2.15678
--------------------------------------------------------
EPOCH 12
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 12%|█▏        | 12/100 [01:22&lt;10:14,  6.98s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 12: LOSS=2.13329
--------------------------------------------------------
EPOCH 13
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 13%|█▎        | 13/100 [01:29&lt;10:08,  6.99s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 13: LOSS=2.11015
--------------------------------------------------------
EPOCH 14
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 14%|█▍        | 14/100 [01:35&lt;09:54,  6.91s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 14: LOSS=2.08944
--------------------------------------------------------
EPOCH 15
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 15%|█▌        | 15/100 [01:43&lt;10:10,  7.18s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 15: LOSS=2.06968
--------------------------------------------------------
EPOCH 16
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 16%|█▌        | 16/100 [01:50&lt;10:00,  7.15s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 16: LOSS=2.05117
--------------------------------------------------------
EPOCH 17
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 17%|█▋        | 17/100 [01:57&lt;09:46,  7.07s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 17: LOSS=2.03224
--------------------------------------------------------
EPOCH 18
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 18%|█▊        | 18/100 [02:04&lt;09:34,  7.00s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 18: LOSS=2.01423
--------------------------------------------------------
EPOCH 19
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 19%|█▉        | 19/100 [02:11&lt;09:24,  6.97s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 19: LOSS=1.99642
--------------------------------------------------------
EPOCH 20
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 20%|██        | 20/100 [02:18&lt;09:18,  6.99s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 20: LOSS=1.97965
--------------------------------------------------------
EPOCH 21
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 21%|██        | 21/100 [02:25&lt;09:07,  6.94s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 21: LOSS=1.96248
--------------------------------------------------------
EPOCH 22
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 22%|██▏       | 22/100 [02:32&lt;08:59,  6.92s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 22: LOSS=1.94670
--------------------------------------------------------
EPOCH 23
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 23%|██▎       | 23/100 [02:39&lt;09:00,  7.02s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 23: LOSS=1.93074
--------------------------------------------------------
EPOCH 24
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 24%|██▍       | 24/100 [02:46&lt;09:07,  7.20s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 24: LOSS=1.91624
--------------------------------------------------------
EPOCH 25
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 25%|██▌       | 25/100 [02:53&lt;08:55,  7.15s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 25: LOSS=1.90246
--------------------------------------------------------
EPOCH 26
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 26%|██▌       | 26/100 [03:00&lt;08:45,  7.10s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 26: LOSS=1.88736
--------------------------------------------------------
EPOCH 27
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 27%|██▋       | 27/100 [03:08&lt;08:38,  7.10s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 27: LOSS=1.87312
--------------------------------------------------------
EPOCH 28
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 28%|██▊       | 28/100 [03:15&lt;08:31,  7.10s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 28: LOSS=1.85814
--------------------------------------------------------
EPOCH 29
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 29%|██▉       | 29/100 [03:22&lt;08:32,  7.22s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 29: LOSS=1.84455
--------------------------------------------------------
EPOCH 30
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 30%|███       | 30/100 [03:29&lt;08:14,  7.07s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 30: LOSS=1.83083
--------------------------------------------------------
EPOCH 31
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 31%|███       | 31/100 [03:36&lt;07:59,  6.95s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 31: LOSS=1.81682
--------------------------------------------------------
EPOCH 32
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 32%|███▏      | 32/100 [03:43&lt;07:58,  7.03s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 32: LOSS=1.80451
--------------------------------------------------------
EPOCH 33
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 33%|███▎      | 33/100 [03:50&lt;07:54,  7.09s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 33: LOSS=1.79022
--------------------------------------------------------
EPOCH 34
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 34%|███▍      | 34/100 [03:57&lt;07:45,  7.05s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 34: LOSS=1.77817
--------------------------------------------------------
EPOCH 35
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 35%|███▌      | 35/100 [04:04&lt;07:37,  7.04s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 35: LOSS=1.76454
--------------------------------------------------------
EPOCH 36
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 36%|███▌      | 36/100 [04:11&lt;07:28,  7.01s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 36: LOSS=1.75081
--------------------------------------------------------
EPOCH 37
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 37%|███▋      | 37/100 [04:19&lt;07:34,  7.22s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 37: LOSS=1.73887
--------------------------------------------------------
EPOCH 38
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 38%|███▊      | 38/100 [04:25&lt;07:21,  7.12s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 38: LOSS=1.72622
--------------------------------------------------------
EPOCH 39
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 39%|███▉      | 39/100 [04:32&lt;07:09,  7.05s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 39: LOSS=1.71504
--------------------------------------------------------
EPOCH 40
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 40%|████      | 40/100 [04:40&lt;07:06,  7.12s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 40: LOSS=1.70258
--------------------------------------------------------
EPOCH 41
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 41%|████      | 41/100 [04:46&lt;06:50,  6.96s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 41: LOSS=1.69242
--------------------------------------------------------
EPOCH 42
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 42%|████▏     | 42/100 [04:54&lt;06:49,  7.06s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 42: LOSS=1.68099
--------------------------------------------------------
EPOCH 43
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 43%|████▎     | 43/100 [05:00&lt;06:38,  6.99s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 43: LOSS=1.66983
--------------------------------------------------------
EPOCH 44
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 44%|████▍     | 44/100 [05:07&lt;06:29,  6.96s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 44: LOSS=1.65832
--------------------------------------------------------
EPOCH 45
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 45%|████▌     | 45/100 [05:14&lt;06:21,  6.94s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 45: LOSS=1.64753
--------------------------------------------------------
EPOCH 46
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 46%|████▌     | 46/100 [05:21&lt;06:12,  6.90s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 46: LOSS=1.63689
--------------------------------------------------------
EPOCH 47
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 47%|████▋     | 47/100 [05:28&lt;06:05,  6.89s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 47: LOSS=1.62782
--------------------------------------------------------
EPOCH 48
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 48%|████▊     | 48/100 [05:34&lt;05:53,  6.79s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 48: LOSS=1.61655
--------------------------------------------------------
EPOCH 49
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 49%|████▉     | 49/100 [05:42&lt;05:53,  6.94s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 49: LOSS=1.60632
--------------------------------------------------------
EPOCH 50
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 50%|█████     | 50/100 [05:49&lt;05:46,  6.92s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 50: LOSS=1.59681
--------------------------------------------------------
EPOCH 51
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 51%|█████     | 51/100 [05:55&lt;05:37,  6.89s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 51: LOSS=1.58720
--------------------------------------------------------
EPOCH 52
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 52%|█████▏    | 52/100 [06:02&lt;05:27,  6.83s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 52: LOSS=1.57817
--------------------------------------------------------
EPOCH 53
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 53%|█████▎    | 53/100 [06:09&lt;05:17,  6.75s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 53: LOSS=1.56839
--------------------------------------------------------
EPOCH 54
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 54%|█████▍    | 54/100 [06:15&lt;05:06,  6.67s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 54: LOSS=1.55952
--------------------------------------------------------
EPOCH 55
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 55%|█████▌    | 55/100 [06:21&lt;04:56,  6.58s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 55: LOSS=1.55179
--------------------------------------------------------
EPOCH 56
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 56%|█████▌    | 56/100 [06:28&lt;04:49,  6.58s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 56: LOSS=1.54211
--------------------------------------------------------
EPOCH 57
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 57%|█████▋    | 57/100 [06:35&lt;04:42,  6.56s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 57: LOSS=1.53133
--------------------------------------------------------
EPOCH 58
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 58%|█████▊    | 58/100 [06:41&lt;04:35,  6.55s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 58: LOSS=1.52345
--------------------------------------------------------
EPOCH 59
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 59%|█████▉    | 59/100 [06:48&lt;04:27,  6.53s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 59: LOSS=1.51453
--------------------------------------------------------
EPOCH 60
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 60%|██████    | 60/100 [06:54&lt;04:18,  6.47s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 60: LOSS=1.50648
--------------------------------------------------------
EPOCH 61
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 61%|██████    | 61/100 [07:01&lt;04:14,  6.52s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 61: LOSS=1.49838
--------------------------------------------------------
EPOCH 62
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 62%|██████▏   | 62/100 [07:07&lt;04:07,  6.50s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 62: LOSS=1.48960
--------------------------------------------------------
EPOCH 63
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 63%|██████▎   | 63/100 [07:14&lt;04:01,  6.53s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 63: LOSS=1.48082
--------------------------------------------------------
EPOCH 64
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 64%|██████▍   | 64/100 [07:21&lt;03:59,  6.64s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 64: LOSS=1.47425
--------------------------------------------------------
EPOCH 65
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 65%|██████▌   | 65/100 [07:28&lt;04:00,  6.86s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 65: LOSS=1.46543
--------------------------------------------------------
EPOCH 66
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 66%|██████▌   | 66/100 [07:35&lt;03:58,  7.02s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 66: LOSS=1.45702
--------------------------------------------------------
EPOCH 67
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 67%|██████▋   | 67/100 [07:43&lt;03:54,  7.11s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 67: LOSS=1.44927
--------------------------------------------------------
EPOCH 68
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 68%|██████▊   | 68/100 [07:49&lt;03:41,  6.91s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 68: LOSS=1.44185
--------------------------------------------------------
EPOCH 69
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 69%|██████▉   | 69/100 [07:55&lt;03:28,  6.73s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 69: LOSS=1.43385
--------------------------------------------------------
EPOCH 70
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 70%|███████   | 70/100 [08:02&lt;03:21,  6.72s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 70: LOSS=1.42711
--------------------------------------------------------
EPOCH 71
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 71%|███████   | 71/100 [08:09&lt;03:13,  6.67s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 71: LOSS=1.41897
--------------------------------------------------------
EPOCH 72
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 72%|███████▏  | 72/100 [08:16&lt;03:12,  6.87s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 72: LOSS=1.41135
--------------------------------------------------------
EPOCH 73
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 73%|███████▎  | 73/100 [08:24&lt;03:11,  7.11s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 73: LOSS=1.40472
--------------------------------------------------------
EPOCH 74
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 74%|███████▍  | 74/100 [08:30&lt;03:02,  7.03s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 74: LOSS=1.39800
--------------------------------------------------------
EPOCH 75
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 75%|███████▌  | 75/100 [08:37&lt;02:52,  6.90s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 75: LOSS=1.39094
--------------------------------------------------------
EPOCH 76
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 76%|███████▌  | 76/100 [08:43&lt;02:38,  6.61s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 76: LOSS=1.38453
--------------------------------------------------------
EPOCH 77
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 77%|███████▋  | 77/100 [08:50&lt;02:34,  6.71s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 77: LOSS=1.37715
--------------------------------------------------------
EPOCH 78
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 78%|███████▊  | 78/100 [08:56&lt;02:24,  6.57s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 78: LOSS=1.37000
--------------------------------------------------------
EPOCH 79
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 79%|███████▉  | 79/100 [09:02&lt;02:12,  6.33s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 79: LOSS=1.36330
--------------------------------------------------------
EPOCH 80
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 80%|████████  | 80/100 [09:07&lt;02:00,  6.05s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 80: LOSS=1.35700
--------------------------------------------------------
EPOCH 81
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 81%|████████  | 81/100 [09:14&lt;01:59,  6.27s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 81: LOSS=1.34961
--------------------------------------------------------
EPOCH 82
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 82%|████████▏ | 82/100 [09:21&lt;01:57,  6.53s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 82: LOSS=1.34357
--------------------------------------------------------
EPOCH 83
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 83%|████████▎ | 83/100 [09:28&lt;01:52,  6.59s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 83: LOSS=1.33732
--------------------------------------------------------
EPOCH 84
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 84%|████████▍ | 84/100 [09:35&lt;01:45,  6.61s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 84: LOSS=1.33051
--------------------------------------------------------
EPOCH 85
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 85%|████████▌ | 85/100 [09:41&lt;01:39,  6.65s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 85: LOSS=1.32431
--------------------------------------------------------
EPOCH 86
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 86%|████████▌ | 86/100 [09:48&lt;01:32,  6.57s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 86: LOSS=1.31801
--------------------------------------------------------
EPOCH 87
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 87%|████████▋ | 87/100 [09:55&lt;01:26,  6.65s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 87: LOSS=1.31209
--------------------------------------------------------
EPOCH 88
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 88%|████████▊ | 88/100 [10:02&lt;01:23,  6.94s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 88: LOSS=1.30424
--------------------------------------------------------
EPOCH 89
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 89%|████████▉ | 89/100 [10:09&lt;01:15,  6.84s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 89: LOSS=1.29828
--------------------------------------------------------
EPOCH 90
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 90%|█████████ | 90/100 [10:15&lt;01:06,  6.70s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 90: LOSS=1.29306
--------------------------------------------------------
EPOCH 91
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 91%|█████████ | 91/100 [10:22&lt;00:59,  6.64s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 91: LOSS=1.28684
--------------------------------------------------------
EPOCH 92
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 92%|█████████▏| 92/100 [10:29&lt;00:53,  6.73s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 92: LOSS=1.28089
--------------------------------------------------------
EPOCH 93
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 93%|█████████▎| 93/100 [10:36&lt;00:47,  6.81s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 93: LOSS=1.27578
--------------------------------------------------------
EPOCH 94
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 94%|█████████▍| 94/100 [10:43&lt;00:41,  6.84s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 94: LOSS=1.26922
--------------------------------------------------------
EPOCH 95
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 95%|█████████▌| 95/100 [10:49&lt;00:33,  6.77s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 95: LOSS=1.26398
--------------------------------------------------------
EPOCH 96
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 96%|█████████▌| 96/100 [10:56&lt;00:27,  6.81s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 96: LOSS=1.25886
--------------------------------------------------------
EPOCH 97
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 97%|█████████▋| 97/100 [11:02&lt;00:19,  6.67s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 97: LOSS=1.25203
--------------------------------------------------------
EPOCH 98
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 98%|█████████▊| 98/100 [11:09&lt;00:13,  6.60s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 98: LOSS=1.24684
--------------------------------------------------------
EPOCH 99
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 99%|█████████▉| 99/100 [11:15&lt;00:06,  6.51s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 99: LOSS=1.24116
--------------------------------------------------------
EPOCH 100
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 100/100 [11:21&lt;00:00,  6.82s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 100: LOSS=1.23610
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<img alt="../_images/Alt-Filter-and-Fire_Neuron_Model_SNN_23_203.png" src="../_images/Alt-Filter-and-Fire_Neuron_Model_SNN_23_203.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># training and testing accuracies</span>
<span class="n">Exp1Fast_train_accuracy</span> <span class="o">=</span> <span class="n">analyse_accuracy</span><span class="p">(</span><span class="n">ipds_train</span><span class="p">,</span> <span class="n">spikes_train</span><span class="p">,</span> <span class="n">Exp1_W1_trained</span><span class="p">,</span> <span class="n">W1_bis</span><span class="p">,</span> <span class="n">Exp1_W2_trained</span><span class="p">,</span> 
                                           <span class="n">multiple_connections_per_axon</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">single_neuron_model</span><span class="o">=</span><span class="n">single_neuron_model</span><span class="p">,</span>
                                           <span class="n">test_data</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Generate the test data</span>
<span class="n">ipds_test</span><span class="p">,</span> <span class="n">spikes_test</span> <span class="o">=</span> <span class="n">random_ipd_input_signal</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="o">*</span><span class="n">N_TESTING_BATCHES</span><span class="p">,</span> <span class="n">usual_phase_delays</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">Exp1_test_accuracy</span> <span class="o">=</span> <span class="n">analyse_accuracy</span><span class="p">(</span><span class="n">ipds_test</span><span class="p">,</span> <span class="n">spikes_test</span><span class="p">,</span> <span class="n">Exp1_W1_trained</span><span class="p">,</span> <span class="n">W1_bis</span><span class="p">,</span> <span class="n">Exp1_W2_trained</span><span class="p">,</span> 
                                          <span class="n">multiple_connections_per_axon</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">single_neuron_model</span><span class="o">=</span><span class="n">single_neuron_model</span><span class="p">,</span>
                                          <span class="n">test_data</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train classifier accuracy: 63.3%
Train absolute error: 7.2 deg

Test classifier accuracy: 57.3%
Test absolute error: 7.8 deg
</pre></div>
</div>
<img alt="../_images/Alt-Filter-and-Fire_Neuron_Model_SNN_24_1.png" src="../_images/Alt-Filter-and-Fire_Neuron_Model_SNN_24_1.png" />
<img alt="../_images/Alt-Filter-and-Fire_Neuron_Model_SNN_24_2.png" src="../_images/Alt-Filter-and-Fire_Neuron_Model_SNN_24_2.png" />
</div>
</div>
</div>
</div>
<div class="section" id="exp-2-training-testing-results">
<h2>Exp 2. Training &amp; Testing Results<a class="headerlink" href="#exp-2-training-testing-results" title="Permalink to this headline">¶</a></h2>
<div class="section" id="using-multiple-connections-m-3">
<h3>Using multiple connections (M=3)<a class="headerlink" href="#using-multiple-connections-m-3" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># training</span>
<span class="c1"># Generate the training data</span>
<span class="n">ipds_train</span><span class="p">,</span> <span class="n">spikes_train</span> <span class="o">=</span> <span class="n">random_ipd_input_signal</span><span class="p">(</span><span class="n">NUM_SAMPLES</span><span class="p">,</span> <span class="n">usual_phase_delays</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">Exp2_W1_trained</span><span class="p">,</span> <span class="n">W1_bis</span><span class="p">,</span> <span class="n">Exp2_W2_trained</span><span class="p">,</span> <span class="n">Exp2_snn_training_snapshot</span><span class="p">,</span> <span class="n">single_neuron_model</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">ipds_train</span><span class="p">,</span> <span class="n">spikes_train</span><span class="p">,</span>
                                                                                         <span class="n">multiple_connections_per_axon</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/100 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--------------------------------------------------------
EPOCH 1
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  1%|          | 1/100 [00:09&lt;16:14,  9.85s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 1: LOSS=2.77975
--------------------------------------------------------
EPOCH 2
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  2%|▏         | 2/100 [00:19&lt;15:33,  9.53s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 2: LOSS=2.48943
--------------------------------------------------------
EPOCH 3
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  3%|▎         | 3/100 [00:28&lt;15:03,  9.31s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 3: LOSS=2.43309
--------------------------------------------------------
EPOCH 4
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  4%|▍         | 4/100 [00:37&lt;14:55,  9.33s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 4: LOSS=2.39790
--------------------------------------------------------
EPOCH 5
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  5%|▌         | 5/100 [00:47&lt;14:52,  9.39s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 5: LOSS=2.36529
--------------------------------------------------------
EPOCH 6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  6%|▌         | 6/100 [00:55&lt;14:24,  9.20s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 6: LOSS=2.33296
--------------------------------------------------------
EPOCH 7
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  7%|▋         | 7/100 [01:04&lt;14:06,  9.10s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 7: LOSS=2.30643
--------------------------------------------------------
EPOCH 8
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  8%|▊         | 8/100 [01:13&lt;13:55,  9.09s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 8: LOSS=2.28021
--------------------------------------------------------
EPOCH 9
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  9%|▉         | 9/100 [01:22&lt;13:34,  8.95s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 9: LOSS=2.25632
--------------------------------------------------------
EPOCH 10
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 10%|█         | 10/100 [01:31&lt;13:14,  8.83s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 10: LOSS=2.23011
--------------------------------------------------------
EPOCH 11
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 11%|█         | 11/100 [01:39&lt;13:08,  8.86s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 11: LOSS=2.20565
--------------------------------------------------------
EPOCH 12
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 12%|█▏        | 12/100 [01:49&lt;13:10,  8.99s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 12: LOSS=2.18536
--------------------------------------------------------
EPOCH 13
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 13%|█▎        | 13/100 [01:58&lt;13:07,  9.05s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 13: LOSS=2.15993
--------------------------------------------------------
EPOCH 14
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 14%|█▍        | 14/100 [02:08&lt;13:13,  9.23s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 14: LOSS=2.13865
--------------------------------------------------------
EPOCH 15
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 15%|█▌        | 15/100 [02:17&lt;13:19,  9.40s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 15: LOSS=2.11837
--------------------------------------------------------
EPOCH 16
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 16%|█▌        | 16/100 [02:27&lt;13:15,  9.47s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 16: LOSS=2.09663
--------------------------------------------------------
EPOCH 17
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 17%|█▋        | 17/100 [02:36&lt;13:03,  9.44s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 17: LOSS=2.07650
--------------------------------------------------------
EPOCH 18
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 18%|█▊        | 18/100 [02:46&lt;12:52,  9.42s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 18: LOSS=2.05805
--------------------------------------------------------
EPOCH 19
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 19%|█▉        | 19/100 [02:56&lt;12:50,  9.52s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 19: LOSS=2.03774
--------------------------------------------------------
EPOCH 20
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 20%|██        | 20/100 [03:05&lt;12:40,  9.50s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 20: LOSS=2.01751
--------------------------------------------------------
EPOCH 21
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 21%|██        | 21/100 [03:15&lt;12:32,  9.52s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 21: LOSS=1.99678
--------------------------------------------------------
EPOCH 22
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 22%|██▏       | 22/100 [03:24&lt;12:32,  9.65s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 22: LOSS=1.97186
--------------------------------------------------------
EPOCH 23
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 23%|██▎       | 23/100 [03:34&lt;12:22,  9.64s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 23: LOSS=1.95140
--------------------------------------------------------
EPOCH 24
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 24%|██▍       | 24/100 [03:43&lt;11:51,  9.36s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 24: LOSS=1.93431
--------------------------------------------------------
EPOCH 25
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 25%|██▌       | 25/100 [03:52&lt;11:47,  9.43s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 25: LOSS=1.91304
--------------------------------------------------------
EPOCH 26
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 26%|██▌       | 26/100 [04:02&lt;11:42,  9.49s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 26: LOSS=1.89475
--------------------------------------------------------
EPOCH 27
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 27%|██▋       | 27/100 [04:13&lt;11:59,  9.86s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 27: LOSS=1.87521
--------------------------------------------------------
EPOCH 28
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 28%|██▊       | 28/100 [04:23&lt;11:49,  9.85s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 28: LOSS=1.85788
--------------------------------------------------------
EPOCH 29
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 29%|██▉       | 29/100 [04:32&lt;11:34,  9.78s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 29: LOSS=1.84079
--------------------------------------------------------
EPOCH 30
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 30%|███       | 30/100 [04:41&lt;11:08,  9.55s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 30: LOSS=1.82494
--------------------------------------------------------
EPOCH 31
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 31%|███       | 31/100 [04:50&lt;10:45,  9.36s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 31: LOSS=1.80928
--------------------------------------------------------
EPOCH 32
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 32%|███▏      | 32/100 [04:59&lt;10:24,  9.18s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 32: LOSS=1.79311
--------------------------------------------------------
EPOCH 33
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 33%|███▎      | 33/100 [05:08&lt;10:07,  9.07s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 33: LOSS=1.77583
--------------------------------------------------------
EPOCH 34
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 34%|███▍      | 34/100 [05:17&lt;09:57,  9.06s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 34: LOSS=1.75982
--------------------------------------------------------
EPOCH 35
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 35%|███▌      | 35/100 [05:26&lt;09:45,  9.00s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 35: LOSS=1.74054
--------------------------------------------------------
EPOCH 36
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 36%|███▌      | 36/100 [05:34&lt;09:29,  8.89s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 36: LOSS=1.72292
--------------------------------------------------------
EPOCH 37
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 37%|███▋      | 37/100 [05:43&lt;09:21,  8.91s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 37: LOSS=1.70417
--------------------------------------------------------
EPOCH 38
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 38%|███▊      | 38/100 [05:52&lt;09:10,  8.87s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 38: LOSS=1.68707
--------------------------------------------------------
EPOCH 39
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 39%|███▉      | 39/100 [06:01&lt;08:59,  8.85s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 39: LOSS=1.67016
--------------------------------------------------------
EPOCH 40
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 40%|████      | 40/100 [06:10&lt;09:03,  9.06s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 40: LOSS=1.65586
--------------------------------------------------------
EPOCH 41
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 41%|████      | 41/100 [06:19&lt;08:55,  9.07s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 41: LOSS=1.64253
--------------------------------------------------------
EPOCH 42
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 42%|████▏     | 42/100 [06:28&lt;08:45,  9.06s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 42: LOSS=1.62788
--------------------------------------------------------
EPOCH 43
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 43%|████▎     | 43/100 [06:37&lt;08:31,  8.97s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 43: LOSS=1.61478
--------------------------------------------------------
EPOCH 44
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 44%|████▍     | 44/100 [06:46&lt;08:20,  8.94s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 44: LOSS=1.60126
--------------------------------------------------------
EPOCH 45
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 45%|████▌     | 45/100 [06:55&lt;08:11,  8.94s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 45: LOSS=1.59007
--------------------------------------------------------
EPOCH 46
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 46%|████▌     | 46/100 [07:04&lt;08:00,  8.89s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 46: LOSS=1.57802
--------------------------------------------------------
EPOCH 47
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 47%|████▋     | 47/100 [07:13&lt;07:51,  8.90s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 47: LOSS=1.56665
--------------------------------------------------------
EPOCH 48
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 48%|████▊     | 48/100 [07:22&lt;07:40,  8.86s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 48: LOSS=1.55513
--------------------------------------------------------
EPOCH 49
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 49%|████▉     | 49/100 [07:30&lt;07:31,  8.85s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 49: LOSS=1.54493
--------------------------------------------------------
EPOCH 50
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 50%|█████     | 50/100 [07:39&lt;07:19,  8.79s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 50: LOSS=1.53372
--------------------------------------------------------
EPOCH 51
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 51%|█████     | 51/100 [07:48&lt;07:07,  8.72s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 51: LOSS=1.52248
--------------------------------------------------------
EPOCH 52
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 52%|█████▏    | 52/100 [07:56&lt;06:59,  8.75s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 52: LOSS=1.51212
--------------------------------------------------------
EPOCH 53
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 53%|█████▎    | 53/100 [08:06&lt;07:01,  8.97s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 53: LOSS=1.50200
--------------------------------------------------------
EPOCH 54
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 54%|█████▍    | 54/100 [08:15&lt;07:01,  9.17s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 54: LOSS=1.49226
--------------------------------------------------------
EPOCH 55
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 55%|█████▌    | 55/100 [08:25&lt;06:57,  9.28s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 55: LOSS=1.48441
--------------------------------------------------------
EPOCH 56
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 56%|█████▌    | 56/100 [08:34&lt;06:41,  9.13s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 56: LOSS=1.47373
--------------------------------------------------------
EPOCH 57
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 57%|█████▋    | 57/100 [08:43&lt;06:31,  9.11s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 57: LOSS=1.46426
--------------------------------------------------------
EPOCH 58
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 58%|█████▊    | 58/100 [08:52&lt;06:22,  9.11s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 58: LOSS=1.45492
--------------------------------------------------------
EPOCH 59
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 59%|█████▉    | 59/100 [09:01&lt;06:15,  9.15s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 59: LOSS=1.44661
--------------------------------------------------------
EPOCH 60
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 60%|██████    | 60/100 [09:10&lt;06:03,  9.09s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 60: LOSS=1.43711
--------------------------------------------------------
EPOCH 61
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 61%|██████    | 61/100 [09:20&lt;06:03,  9.31s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 61: LOSS=1.42963
--------------------------------------------------------
EPOCH 62
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 62%|██████▏   | 62/100 [09:29&lt;05:47,  9.15s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 62: LOSS=1.42165
--------------------------------------------------------
EPOCH 63
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 63%|██████▎   | 63/100 [09:38&lt;05:36,  9.09s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 63: LOSS=1.41403
--------------------------------------------------------
EPOCH 64
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 64%|██████▍   | 64/100 [09:48&lt;05:45,  9.60s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 64: LOSS=1.40536
--------------------------------------------------------
EPOCH 65
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 65%|██████▌   | 65/100 [09:59&lt;05:44,  9.85s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 65: LOSS=1.39788
--------------------------------------------------------
EPOCH 66
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 66%|██████▌   | 66/100 [10:10&lt;05:43, 10.11s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 66: LOSS=1.39010
--------------------------------------------------------
EPOCH 67
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 67%|██████▋   | 67/100 [10:20&lt;05:37, 10.24s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 67: LOSS=1.38253
--------------------------------------------------------
EPOCH 68
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 68%|██████▊   | 68/100 [10:31&lt;05:31, 10.37s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 68: LOSS=1.37322
--------------------------------------------------------
EPOCH 69
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 69%|██████▉   | 69/100 [10:44&lt;05:45, 11.15s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 69: LOSS=1.36716
--------------------------------------------------------
EPOCH 70
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 70%|███████   | 70/100 [10:56&lt;05:42, 11.40s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 70: LOSS=1.35901
--------------------------------------------------------
EPOCH 71
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 71%|███████   | 71/100 [11:08&lt;05:36, 11.60s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 71: LOSS=1.35109
--------------------------------------------------------
EPOCH 72
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 72%|███████▏  | 72/100 [11:21&lt;05:33, 11.92s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 72: LOSS=1.34413
--------------------------------------------------------
EPOCH 73
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 73%|███████▎  | 73/100 [11:30&lt;05:03, 11.24s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 73: LOSS=1.33700
--------------------------------------------------------
EPOCH 74
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 74%|███████▍  | 74/100 [11:40&lt;04:37, 10.69s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 74: LOSS=1.33069
--------------------------------------------------------
EPOCH 75
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 75%|███████▌  | 75/100 [11:49&lt;04:16, 10.28s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 75: LOSS=1.32303
--------------------------------------------------------
EPOCH 76
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 76%|███████▌  | 76/100 [12:00&lt;04:09, 10.41s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 76: LOSS=1.31761
--------------------------------------------------------
EPOCH 77
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 77%|███████▋  | 77/100 [12:09&lt;03:55, 10.22s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 77: LOSS=1.30953
--------------------------------------------------------
EPOCH 78
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 78%|███████▊  | 78/100 [12:19&lt;03:40, 10.04s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 78: LOSS=1.30399
--------------------------------------------------------
EPOCH 79
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 79%|███████▉  | 79/100 [12:29&lt;03:30, 10.01s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 79: LOSS=1.29726
--------------------------------------------------------
EPOCH 80
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 80%|████████  | 80/100 [12:39&lt;03:20, 10.04s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 80: LOSS=1.29030
--------------------------------------------------------
EPOCH 81
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 81%|████████  | 81/100 [12:50&lt;03:17, 10.39s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 81: LOSS=1.28427
--------------------------------------------------------
EPOCH 82
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 82%|████████▏ | 82/100 [13:00&lt;03:04, 10.25s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 82: LOSS=1.27807
--------------------------------------------------------
EPOCH 83
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 83%|████████▎ | 83/100 [13:10&lt;02:52, 10.13s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 83: LOSS=1.27155
--------------------------------------------------------
EPOCH 84
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 84%|████████▍ | 84/100 [13:20&lt;02:39,  9.96s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 84: LOSS=1.26524
--------------------------------------------------------
EPOCH 85
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 85%|████████▌ | 85/100 [13:29&lt;02:25,  9.73s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 85: LOSS=1.26003
--------------------------------------------------------
EPOCH 86
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 86%|████████▌ | 86/100 [13:38&lt;02:14,  9.59s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 86: LOSS=1.25504
--------------------------------------------------------
EPOCH 87
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 87%|████████▋ | 87/100 [13:47&lt;02:03,  9.53s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 87: LOSS=1.24881
--------------------------------------------------------
EPOCH 88
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 88%|████████▊ | 88/100 [13:57&lt;01:53,  9.46s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 88: LOSS=1.24128
--------------------------------------------------------
EPOCH 89
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 89%|████████▉ | 89/100 [14:07&lt;01:46,  9.65s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 89: LOSS=1.23756
--------------------------------------------------------
EPOCH 90
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 90%|█████████ | 90/100 [14:18&lt;01:40, 10.03s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 90: LOSS=1.23236
--------------------------------------------------------
EPOCH 91
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 91%|█████████ | 91/100 [14:27&lt;01:29,  9.91s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 91: LOSS=1.22519
--------------------------------------------------------
EPOCH 92
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 92%|█████████▏| 92/100 [14:37&lt;01:17,  9.73s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 92: LOSS=1.22161
--------------------------------------------------------
EPOCH 93
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 93%|█████████▎| 93/100 [14:46&lt;01:06,  9.51s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 93: LOSS=1.21654
--------------------------------------------------------
EPOCH 94
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 94%|█████████▍| 94/100 [14:55&lt;00:57,  9.54s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 94: LOSS=1.21127
--------------------------------------------------------
EPOCH 95
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 95%|█████████▌| 95/100 [15:05&lt;00:47,  9.45s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 95: LOSS=1.20618
--------------------------------------------------------
EPOCH 96
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 96%|█████████▌| 96/100 [15:14&lt;00:37,  9.45s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 96: LOSS=1.20015
--------------------------------------------------------
EPOCH 97
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 97%|█████████▋| 97/100 [15:23&lt;00:28,  9.38s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 97: LOSS=1.19487
--------------------------------------------------------
EPOCH 98
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 98%|█████████▊| 98/100 [15:32&lt;00:18,  9.31s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 98: LOSS=1.19023
--------------------------------------------------------
EPOCH 99
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 99%|█████████▉| 99/100 [15:42&lt;00:09,  9.33s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 99: LOSS=1.18684
--------------------------------------------------------
EPOCH 100
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 100/100 [15:51&lt;00:00,  9.52s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>---EPOCH 100: LOSS=1.18137
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<img alt="../_images/Alt-Filter-and-Fire_Neuron_Model_SNN_27_203.png" src="../_images/Alt-Filter-and-Fire_Neuron_Model_SNN_27_203.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># training and testing accuracies</span>
<span class="n">Exp2_train_accuracy</span> <span class="o">=</span> <span class="n">analyse_accuracy</span><span class="p">(</span><span class="n">ipds_train</span><span class="p">,</span> <span class="n">spikes_train</span><span class="p">,</span> <span class="n">Exp2_W1_trained</span><span class="p">,</span> <span class="n">W1_bis</span><span class="p">,</span> <span class="n">Exp2_W2_trained</span><span class="p">,</span> 
                                           <span class="n">multiple_connections_per_axon</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">single_neuron_model</span><span class="o">=</span><span class="n">single_neuron_model</span><span class="p">,</span>
                                           <span class="n">test_data</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Generate the test data</span>
<span class="n">ipds_test</span><span class="p">,</span> <span class="n">spikes_test</span> <span class="o">=</span> <span class="n">random_ipd_input_signal</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="o">*</span><span class="n">N_TESTING_BATCHES</span><span class="p">,</span> <span class="n">usual_phase_delays</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">Exp2_test_accuracy</span> <span class="o">=</span> <span class="n">analyse_accuracy</span><span class="p">(</span><span class="n">ipds_test</span><span class="p">,</span> <span class="n">spikes_test</span><span class="p">,</span> <span class="n">Exp2_W1_trained</span><span class="p">,</span> <span class="n">W1_bis</span><span class="p">,</span> <span class="n">Exp2_W2_trained</span><span class="p">,</span> 
                                          <span class="n">multiple_connections_per_axon</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">single_neuron_model</span><span class="o">=</span><span class="n">single_neuron_model</span><span class="p">,</span>
                                          <span class="n">test_data</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train classifier accuracy: 65.6%
Train absolute error: 6.9 deg

Test classifier accuracy: 31.1%
Test absolute error: 16.9 deg
</pre></div>
</div>
<img alt="../_images/Alt-Filter-and-Fire_Neuron_Model_SNN_28_1.png" src="../_images/Alt-Filter-and-Fire_Neuron_Model_SNN_28_1.png" />
<img alt="../_images/Alt-Filter-and-Fire_Neuron_Model_SNN_28_2.png" src="../_images/Alt-Filter-and-Fire_Neuron_Model_SNN_28_2.png" />
</div>
</div>
</div>
</div>
<div class="section" id="results">
<h2>Results<a class="headerlink" href="#results" title="Permalink to this headline">¶</a></h2>
<p>Currently the model with the multiple contacts (here M=3), achieves marginally better training accuracy (65.6%) than the training accuracy (63.3%) of the no multiple contacts model (M=1), but its test accuracy is much worse (57.3% vs 31.1%).</p>
<p>However, it seems that the multiple contacts model overfits to the data.
We should possibly add some regularization means, or check out the hyper-parameters we are using.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./research"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="Altering_output_neurons.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Altering Output Neurons</p>
        </div>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By COMOB, the project for collaborative modelling of the brain<br/>
    
      <div class="extra_footer">
        <small>
  Licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC-BY-SA</a>:
  You may use this work, with attribution, in other freely available works.
</small>

      </div>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>